{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb230cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this code we will see the performance of the Decision Tree Regressor Vs Bagging Regressor\n",
    "\n",
    "## Importing the Dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn import datasets ## For dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef9219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos = datasets.load_boston()\n",
    "\n",
    "x,y = bos.data, bos.target\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6872b47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16943d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Features Name :  ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "Dataset Feature Size :  (506, 13)\n",
      "Dataset Target Size :  (506,)\n"
     ]
    }
   ],
   "source": [
    "print('Dataset Features Name : ', bos.feature_names)\n",
    "print('Dataset Feature Size : ', bos.data.shape)\n",
    "print('Dataset Target Size : ', bos.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "461f7ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Sets Sizes :  (404, 13) (102, 13) (404,) (102,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "## Splitting the Data\n",
    "\n",
    "x_train, x_test, y_train,y_test = train_test_split(x,y, train_size=0.8, random_state= 10)\n",
    "\n",
    "print('Train/Test Sets Sizes : ',x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19299eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating Model Object\n",
    "\n",
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "## Fitting the Model Object\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "dt.fit(x_train,y_train)\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c554e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction\n",
    "\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "y_pred_dt = dt.predict(x_test)\n",
    "y_pred_knn = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b387890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-Score for LR :  0.670933983911564\n",
      "R2-Score for DT :  0.6968896098880019\n",
      "R2-Score for KNN :  0.4242299200856059\n"
     ]
    }
   ],
   "source": [
    "## Calculating the R2 Score\n",
    "\n",
    "print('R2-Score for LR : ', r2_score(y_test,y_pred_lr))\n",
    "print('R2-Score for DT : ', r2_score(y_test,y_pred_dt))\n",
    "print('R2-Score for KNN : ', r2_score(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88f1b86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(random_state=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bagging Regression\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bag_reg = BaggingRegressor(random_state=1) # Using Default Values \n",
    "\n",
    "bag_reg.fit(x_train,y_train) ## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5235d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2-Score for Bag_Reg :  0.9735038707697211\n",
      "Testing R2-Score for Bag_Reg :  0.8514481322021376\n"
     ]
    }
   ],
   "source": [
    "y_pred_bag = bag_reg.predict(x_test) ## prediction\n",
    "\n",
    "print('Training R2-Score for Bag_Reg : ', bag_reg.score(x_train, y_train))\n",
    "print('Testing R2-Score for Bag_Reg : ', r2_score(y_test,y_pred_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9cc8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can observe that even without passing any particular hyperparamets, the bagging regressor is giving better\n",
    "## results than all of the above alogirith with training score of 97% and testing score of 85%\n",
    "## So we can do hyper parameter tunning and work with these parameters to get the optimum result or we can use\n",
    "## GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faf04c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=BaggingRegressor(n_jobs=-1, random_state=10),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'base_estimator': [None, LinearRegression(),\n",
       "                                            KNeighborsRegressor()],\n",
       "                         'bootstrap': [True, False],\n",
       "                         'bootstrap_features': [True, False],\n",
       "                         'max_features': [0.5, 1.0], 'max_samples': [0.5, 1.0],\n",
       "                         'n_estimators': [20, 50, 100]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using GridSearchCV()\n",
    "\n",
    "param = prams = {'base_estimator' : [None ,LinearRegression(), KNeighborsRegressor()],# None = DecisionTree(Default)\n",
    "        'n_estimators' : [20,50,100],\n",
    "        'max_samples': [0.5,1.0],\n",
    "        'max_features' : [0.5,1.0],\n",
    "        'bootstrap':[True, False],\n",
    "        'bootstrap_features':[True, False]   \n",
    "                }\n",
    "bag_reg_grid = GridSearchCV(BaggingRegressor(random_state=10, n_jobs=-1),\n",
    "                            param_grid=prams, \n",
    "                            cv =5,\n",
    "                            verbose=True,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "bag_reg_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdc03892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing R2-Score after Tunning :  0.9999968295541297\n",
      "Testing R2-Score after Tunning :  0.7795229962668736\n"
     ]
    }
   ],
   "source": [
    "print('Traing R2-Score after Tunning : ', bag_reg_grid.best_estimator_.score(x_train,y_train))\n",
    "print('Testing R2-Score after Tunning : ', bag_reg_grid.best_estimator_.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fab9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters :  {'base_estimator': None, 'bootstrap': False, 'bootstrap_features': True, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters : ', bag_reg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7fefe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## So we can try different combination as observe the result is an overfitting model with low testing score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41b908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
